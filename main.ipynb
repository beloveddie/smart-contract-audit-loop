{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN35hWtdOKYhDGZUx1c0ENN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beloveddie/smart-contract-audit-loop/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human-in-the-Loop Smart Contract Auditing Workflow\n",
        "\n",
        "built using the LlamaIndex's Workflow API...\n",
        "\n",
        "_modeled after your [story-crafting notebook](https://github.com/beloveddie/AI-Craft/blob/main/docs/docs/examples/workflow/human_in_the_loop_story_crafting.ipynb)._"
      ],
      "metadata": {
        "id": "zdMlQ6nFhAsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧱 STEP 1: Define the Data Model (AuditSegment)\n",
        "\n",
        "We’ll start by creating a structured output model that the LLM will use to:\n",
        "\n",
        "* Summarize the function\n",
        "\n",
        "* Identify potential risks\n",
        "\n",
        "* Suggest improvements"
      ],
      "metadata": {
        "id": "3r6pgoXZg4Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the necessary librarie\n",
        "!pip install llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjZzp8sEhjry",
        "outputId": "eb4f687c-20cd-4cb1-adf0-1501a381243e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.12.29-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
            "Collecting llama-index-cli<0.5.0,>=0.4.1 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.29 (from llama-index)\n",
            "  Downloading llama_index_core-0.12.29-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.3.32-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.70.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.29->llama-index) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (3.11.15)\n",
            "Collecting banks<3.0.0,>=2.0.0 (from llama-index-core<0.13.0,>=0.12.29->llama-index)\n",
            "  Downloading banks-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.29->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.29->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.29->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (2.11.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (9.1.2)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.29->llama-index)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (4.13.1)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.29->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.29->llama-index) (1.17.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.18-py3-none-any.whl.metadata (902 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.29->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.29->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.29->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.29->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.29->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.29->llama-index) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.29->llama-index) (1.18.3)\n",
            "Collecting griffe (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.29->llama-index)\n",
            "  Downloading griffe-1.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.29->llama-index) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.29->llama-index) (4.3.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.29->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.29->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.29->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.29->llama-index) (0.14.0)\n",
            "Collecting llama-cloud-services>=0.6.4 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.29->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.29->llama-index) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.29->llama-index) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.29->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.29->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.29->llama-index) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.29->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.29->llama-index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.2)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.29->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.29->llama-index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.29->llama-index) (3.0.2)\n",
            "Downloading llama_index-0.12.29-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.29-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_llms_openai-0.3.32-py3-none-any.whl (23 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading banks-2.1.1-py3-none-any.whl (28 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_cloud-0.1.18-py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.4.post1-py3-none-any.whl (4.9 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_cloud_services-0.6.9-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading griffe-1.7.2-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, python-dotenv, pypdf, mypy-extensions, marshmallow, colorama, typing-inspect, tiktoken, griffe, llama-cloud, dataclasses-json, banks, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed banks-2.1.1 colorama-0.4.6 dataclasses-json-0.6.7 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.7.2 llama-cloud-0.1.18 llama-cloud-services-0.6.9 llama-index-0.12.29 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-core-0.12.29 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.32 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.4.post1 marshmallow-3.26.1 mypy-extensions-1.0.0 pypdf-5.4.0 python-dotenv-1.1.0 striprtf-0.0.26 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kLrjga5yg1I4"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
        "\n",
        "class AuditSegment(BaseModel):\n",
        "    \"\"\"Structured audit result for a single function.\"\"\"\n",
        "    summary: str = Field(description=\"A concise explanation of what the function does.\")\n",
        "    risks: List[str] = Field(description=\"A list of potential security vulnerabilities or logical flaws.\")\n",
        "    suggestions: List[str] = Field(description=\"Recommended improvements or fixes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧠 STEP 2: Create the Prompt Template\n",
        "\n",
        "We’ll design the prompt to guide the LLM to generate structured output matching `AuditSegment`."
      ],
      "metadata": {
        "id": "CD1Yt_cViqvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.prompts import PromptTemplate\n",
        "\n",
        "AUDIT_TEMPLATE = \"\"\"\n",
        "You are a smart contract auditor. Analyze the following Solidity function:\n",
        "\n",
        "{function_code}\n",
        "\n",
        "Return your findings in structured format:\n",
        "1. Summary of what the function does,\n",
        "2. List of potential vulnerabilities,\n",
        "3. Suggestions for fixing issues or improving security.\n",
        "\n",
        "Output must match the AuditSegment schema:\n",
        "- summary: string\n",
        "- risks: List of strings\n",
        "- suggestions: List of strings\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WlkYAciHifAN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧭 STEP 3: Define the Auditing Workflow Class\n",
        "We’ll build a class `SmartContractAuditWorkflow`, similar to the [story-crafting one](https://github.com/beloveddie/AI-Craft/blob/main/docs/docs/examples/workflow/human_in_the_loop_story_crafting.ipynb), with two main steps:\n",
        "\n",
        "**⚙️ Workflow Steps:**\n",
        "\n",
        "1. `create_audit_segment` — LLM analyzes a function and outputs an `AuditSegment`.\n",
        "\n",
        "2. `prompt_human_review` — Human sees the AI's review and gives feedback."
      ],
      "metadata": {
        "id": "ka9NO-UNjhqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set OPENAI_API_KEY from Colab Secrets\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "QroR4poSkHx3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.workflow import (\n",
        "    Context,\n",
        "    Event,\n",
        "    StartEvent,\n",
        "    StopEvent,\n",
        "    Workflow,\n",
        "    step,\n",
        ")\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# -- Your existing AuditSegment model --\n",
        "class AuditSegment(BaseModel):\n",
        "    summary: str = Field(description=\"What the function does.\")\n",
        "    risks: List[str] = Field(description=\"Security or logic risks.\")\n",
        "    suggestions: List[str] = Field(description=\"Fixes or improvements.\")\n",
        "\n",
        "# -- Event classes --\n",
        "class NewAuditEvent(Event):\n",
        "    segment: AuditSegment\n",
        "    function_code: str\n",
        "\n",
        "class HumanReviewEvent(Event):\n",
        "    function_id: str\n",
        "\n",
        "# -- Templates --\n",
        "AUDIT_TEMPLATE = \"\"\"\n",
        "You are a Solidity smart contract auditor. Analyze the following function:\n",
        "\n",
        "{function_code}\n",
        "\n",
        "Return the following:\n",
        "- A brief summary of what it does\n",
        "- A list of potential risks or vulnerabilities\n",
        "- Suggestions to improve the function’s security or design\n",
        "\n",
        "Return as a structured object with:\n",
        "- summary: string\n",
        "- risks: list of strings\n",
        "- suggestions: list of strings\n",
        "\"\"\"\n",
        "\n",
        "FEEDBACK_PROMPT = \"\"\"\n",
        "You previously audited this Solidity function:\n",
        "\n",
        "{function_code}\n",
        "\n",
        "Original Audit Output:\n",
        "SUMMARY:\n",
        "{old_summary}\n",
        "\n",
        "RISKS:\n",
        "{old_risks}\n",
        "\n",
        "SUGGESTIONS:\n",
        "{old_suggestions}\n",
        "\n",
        "A human reviewer provided the following feedback:\n",
        "\"{human_feedback}\"\n",
        "\n",
        "Using the feedback, revise your audit and return a complete structured object like this:\n",
        "\n",
        "{\n",
        "  \"summary\": \"...\",\n",
        "  \"risks\": [\"...\", \"...\"],\n",
        "  \"suggestions\": [\"...\", \"...\"]\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# -- Workflow Definition --\n",
        "class SmartContractAuditWorkflow(Workflow):\n",
        "    def __init__(self, function_codes: List[str], **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.llm = OpenAI(\"gpt-4o-mini\")\n",
        "        self.function_codes = function_codes\n",
        "\n",
        "    @step\n",
        "    async def create_audit_segment(\n",
        "        self, ctx: Context, ev: StartEvent | HumanReviewEvent\n",
        "    ) -> NewAuditEvent | StopEvent:\n",
        "        segments = await ctx.get(\"audit_segments\", [])\n",
        "        index = len(segments)\n",
        "\n",
        "        if index < len(self.function_codes):\n",
        "            code = self.function_codes[index]\n",
        "            audit = self.llm.structured_predict(\n",
        "                AuditSegment,\n",
        "                PromptTemplate(AUDIT_TEMPLATE),\n",
        "                function_code=code,\n",
        "            )\n",
        "            segments.append(audit)\n",
        "            await ctx.set(\"audit_segments\", segments)\n",
        "            return NewAuditEvent(segment=audit, function_code=code)\n",
        "        else:\n",
        "            return StopEvent(result=segments)\n",
        "\n",
        "    @step\n",
        "    async def prompt_human_review(\n",
        "        self, ctx: Context, ev: NewAuditEvent\n",
        "    ) -> HumanReviewEvent:\n",
        "        segment = ev.segment\n",
        "\n",
        "        print(\"\\n📄 Function Code:\\n\", ev.function_code)\n",
        "        print(\"\\n🧠 Summary:\\n\", segment.summary)\n",
        "        print(\"\\n⚠️ Risks:\\n\", \"\\n- \".join(segment.risks))\n",
        "        print(\"\\n🔧 Suggestions:\\n\", \"\\n- \".join(segment.suggestions))\n",
        "\n",
        "        feedback = input(\"\\n💬 Feedback on this audit? Leave blank to accept, or type your comments: \").strip()\n",
        "\n",
        "        if feedback:\n",
        "          while True:\n",
        "              print(\"\\n🔁 Reprocessing audit with your feedback...\\n\")\n",
        "\n",
        "              updated_segment = self.llm.structured_predict(\n",
        "                  AuditSegment,\n",
        "                  PromptTemplate(FEEDBACK_PROMPT),\n",
        "                  function_code=ev.function_code,\n",
        "                  old_summary=segment.summary,\n",
        "                  old_risks=\"\\n\".join(segment.risks),\n",
        "                  old_suggestions=\"\\n\".join(segment.suggestions),\n",
        "                  human_feedback=feedback\n",
        "              )\n",
        "\n",
        "              print(\"✅ Updated Audit Segment:\\n\")\n",
        "              print(\"🧠 Summary:\", updated_segment.summary)\n",
        "              print(\"⚠️ Risks:\\n- \" + \"\\n- \".join(updated_segment.risks))\n",
        "              print(\"🔧 Suggestions:\\n- \" + \"\\n- \".join(updated_segment.suggestions))\n",
        "\n",
        "              segment = updated_segment\n",
        "\n",
        "              feedback = input(\"\\n💬 More feedback? Press Enter to confirm and continue, or type more comments: \").strip()\n",
        "              if not feedback:\n",
        "                  break\n",
        "\n",
        "\n",
        "        # Update the segment in context\n",
        "        segments = await ctx.get(\"audit_segments\")\n",
        "        segments[-1] = segment\n",
        "        await ctx.set(\"audit_segments\", segments)\n",
        "\n",
        "        return HumanReviewEvent(function_id=\"FUNC_\" + str(len(segments)))"
      ],
      "metadata": {
        "id": "rdfrI0aOjAQU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧪 STEP 4: Running the Workflow\n",
        "Here we will:\n",
        "\n",
        "1. Define sample **Solidity functions** to audit,\n",
        "\n",
        "2. Instantiate the workflow with those functions,\n",
        "\n",
        "3. Run it and observe AI + Human interactions."
      ],
      "metadata": {
        "id": "THGkTN_0koB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "\n",
        "# Required in notebooks to allow nested async loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# 🧾 Example Solidity functions for testing\n",
        "function_list = [\n",
        "    \"\"\"\n",
        "    function withdraw() public {\n",
        "    require(balances[msg.sender] > 0, \"No funds to withdraw\");\n",
        "    payable(msg.sender).transfer(balances[msg.sender]);\n",
        "    balances[msg.sender] = 0;\n",
        "    }\n",
        "    \"\"\",\n",
        "    # \"\"\"\n",
        "    # function withdraw() public {\n",
        "    #     require(balances[msg.sender] > 0);\n",
        "    #     payable(msg.sender).transfer(balances[msg.sender]);\n",
        "    #     balances[msg.sender] = 0;\n",
        "    # }\n",
        "    # \"\"\",\n",
        "    # \"\"\"\n",
        "    # function mint(address to, uint256 amount) external onlyOwner {\n",
        "    #     _balances[to] += amount;\n",
        "    #     _totalSupply += amount;\n",
        "    # }\n",
        "    # \"\"\"\n",
        "]\n",
        "\n",
        "# 🚀 Instantiate the workflow\n",
        "audit_workflow = SmartContractAuditWorkflow(function_codes=function_list)\n",
        "\n",
        "# ✅ Run the workflow\n",
        "result = await audit_workflow.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGzbpK2XkNar",
        "outputId": "88f770a8-57eb-4c9f-a57c-2e126dd207d6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📄 Function Code:\n",
            " \n",
            "    function withdraw() public {\n",
            "    require(balances[msg.sender] > 0, \"No funds to withdraw\");\n",
            "    payable(msg.sender).transfer(balances[msg.sender]);\n",
            "    balances[msg.sender] = 0;\n",
            "    }\n",
            "    \n",
            "\n",
            "🧠 Summary:\n",
            " The withdraw function allows users to withdraw their funds from the contract. It checks if the user has a positive balance, transfers the balance to the user's address, and then resets the user's balance to zero.\n",
            "\n",
            "⚠️ Risks:\n",
            " Reentrancy attack: If the recipient is a contract, it could call back into the withdraw function before the balance is set to zero, leading to potential multiple withdrawals.\n",
            "- Gas limit issues: If the transfer fails due to gas limits or other reasons, the user's balance will not be reset, potentially causing issues in future withdrawals.\n",
            "\n",
            "🔧 Suggestions:\n",
            " Implement a checks-effects-interactions pattern to mitigate reentrancy attacks by updating the balance before transferring funds.\n",
            "- Consider using a pull-over-push model where users can claim their funds instead of transferring them directly, reducing the risk of reentrancy.\n",
            "- Add a mechanism to handle failed transfers gracefully, such as emitting an event or reverting the transaction if the transfer fails.\n",
            "\n",
            "💬 Feedback on this audit? Leave blank to accept, or type your comments: reword the summary for greater clarity and conciseness\n",
            "\n",
            "🔁 Reprocessing audit with your feedback...\n",
            "\n",
            "✅ Updated Audit Segment:\n",
            "\n",
            "🧠 Summary: The withdraw function enables users to retrieve their funds from the contract. It verifies that the user has a positive balance, transfers the corresponding amount to the user's address, and subsequently sets the user's balance to zero.\n",
            "⚠️ Risks:\n",
            "- Reentrancy attack: If the recipient is a contract, it could invoke the withdraw function again before the user's balance is reset, allowing for multiple withdrawals.\n",
            "- Gas limit issues: If the transfer fails due to gas limits or other reasons, the user's balance will remain unchanged, potentially causing problems for future withdrawals.\n",
            "🔧 Suggestions:\n",
            "- Implement the checks-effects-interactions pattern to mitigate reentrancy attacks by updating the user's balance before transferring funds.\n",
            "- Consider adopting a pull-over-push model, allowing users to claim their funds instead of transferring them directly, which reduces the risk of reentrancy.\n",
            "- Add a mechanism to handle failed transfers gracefully, such as emitting an event or reverting the transaction if the transfer fails.\n",
            "\n",
            "💬 More feedback? Press Enter to confirm and continue, or type more comments: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ STEP 6: Generate Final Audit Report"
      ],
      "metadata": {
        "id": "diKXdVyBnNSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n📒 FINAL AUDIT REPORT\")\n",
        "for idx, segment in enumerate(result):\n",
        "    print(f\"\\n=== AUDIT: FUNCTION {idx + 1} ===\")\n",
        "    print(\"🧠 Summary:\\n\", segment.summary)\n",
        "    print(\"⚠️ Risks:\")\n",
        "    for r in segment.risks:\n",
        "        print(\"- \" + r)\n",
        "    print(\"🔧 Suggestions:\")\n",
        "    for s in segment.suggestions:\n",
        "        print(\"- \" + s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOzDIIpYk3Q0",
        "outputId": "a9662b5b-9cd8-44d6-ec01-c5d141bc5ecd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📒 FINAL AUDIT REPORT\n",
            "\n",
            "=== AUDIT: FUNCTION 1 ===\n",
            "🧠 Summary:\n",
            " The withdraw function enables users to retrieve their funds from the contract. It verifies that the user has a positive balance, transfers the corresponding amount to the user's address, and subsequently sets the user's balance to zero.\n",
            "⚠️ Risks:\n",
            "- Reentrancy attack: If the recipient is a contract, it could invoke the withdraw function again before the user's balance is reset, allowing for multiple withdrawals.\n",
            "- Gas limit issues: If the transfer fails due to gas limits or other reasons, the user's balance will remain unchanged, potentially causing problems for future withdrawals.\n",
            "🔧 Suggestions:\n",
            "- Implement the checks-effects-interactions pattern to mitigate reentrancy attacks by updating the user's balance before transferring funds.\n",
            "- Consider adopting a pull-over-push model, allowing users to claim their funds instead of transferring them directly, which reduces the risk of reentrancy.\n",
            "- Add a mechanism to handle failed transfers gracefully, such as emitting an event or reverting the transaction if the transfer fails.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "64ZKVg0jnRpk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}